{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromiumService\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [\n",
    "        \"--headless\",\n",
    "        \"--window-size=1920,1200\",\n",
    "        \"--start-maximized\",\n",
    "        \"--no-sandbox\",\n",
    "        \"--disable-dev-shm-usage\",\n",
    "        \"--disable-gpu\",\n",
    "        \"--ignore-certificate-errors\",\n",
    "        \"--disable-extensions\",\n",
    "        \"--disable-popup-blocking\",\n",
    "        \"--disable-notifications\",\n",
    "        \"--remote-debugging-port=9222\", #https://stackoverflow.com/questions/56637973/how-to-fix-selenium-devtoolsactiveport-file-doesnt-exist-exception-in-python\n",
    "        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"\n",
    "        \"--disable-blink-features=AutomationControlled\",\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = ChromiumService(executable_path=r\"C:\\Users\\quant\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\")\n",
    "        \n",
    "chrome_options = Options() \n",
    "for option in options:\n",
    "    chrome_options.add_argument(option)\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ids(data_table):\n",
    "    CLASS_ID = 'Anchor_anchor__cSc3P' #determined by visual inspection of page source code\n",
    "\n",
    "    # get all the links\n",
    "    links = data_table.find_all('a', {'class':CLASS_ID})\n",
    "\n",
    "    links_list = [i.get(\"href\") for i in links]\n",
    "\n",
    "    # create a series using last 10 digits of the appropriate links\n",
    "    team_id = pd.Series([i[-10:] for i in links_list if ('stats' in i)])\n",
    "    game_id = pd.Series([i[-10:] for i in links_list if ('/game/' in i)])\n",
    "    \n",
    "    return team_id, game_id\n",
    "\n",
    "def scrape_to_dataframe(driver, season, dateFrom, dateTo, seasonType):\n",
    "    url = \"https://www.nba.com/stats/teams/boxscores?SeasonType=\" + seasonType\n",
    "    if not season:\n",
    "        url = url + \"&DateFrom=\" + dateFrom + \"&DateTo=\" + dateTo\n",
    "    else:\n",
    "        if dateFrom == \"NONE\" and dateTo == \"NONE\":\n",
    "            url = url + \"&Season=\" + season\n",
    "        else:\n",
    "            url = url + \"&Season=\" + season + \"&DateFrom=\" + dateFrom + \"&DateTo=\" + dateTo\n",
    "\n",
    "    print(f\"Scraping {url}\")\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "    source = soup(driver.page_source, 'html.parser')\n",
    "\n",
    "    CLASS_ID_TABLE = 'Crom_table__p1iZz' #determined by visual inspection of page source code\n",
    "    data_table = source.find('table', {'class':CLASS_ID_TABLE})\n",
    "    if data_table is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    CLASS_ID_PAGINATION = \"Pagination_pageDropdown__KgjBU\" #determined by visual inspection of page source code\n",
    "    pagination = source.find('div', {'class':CLASS_ID_PAGINATION})\n",
    "    if pagination is not None:\n",
    "        # if multiple pages, first activate pulldown option for All pages to show all rows on one page\n",
    "        CLASS_ID_DROPDOWN = \"DropDown_select__4pIg9\" #determined by visual inspection of page source code\n",
    "        page_dropdown = driver.find_element(By.XPATH, \"//*[@class='\" + CLASS_ID_PAGINATION + \"']//*[@class='\" + CLASS_ID_DROPDOWN + \"']\")\n",
    "    \n",
    "        page_dropdown.send_keys(\"ALL\") # show all pages\n",
    "        #page_dropdown.click() doesn't work in headless mode\n",
    "        time.sleep(3)\n",
    "        driver.execute_script('arguments[0].click()', page_dropdown) #click() didn't work in headless mode, used this workaround (https://stackoverflow.com/questions/57741875)\n",
    "        \n",
    "        #refresh page data now that it contains all rows of the table\n",
    "        time.sleep(3)\n",
    "        source = soup(driver.page_source, 'html.parser')\n",
    "        data_table = source.find('table', {'class':CLASS_ID_TABLE})\n",
    "\n",
    "    dfs = pd.read_html(str(data_table), header=0) \n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # pull out teams ids and game ids from hrefs and add these to the dataframe\n",
    "    TEAM_ID, GAME_ID = parse_ids(data_table)\n",
    "    df['TEAM_ID'] = TEAM_ID\n",
    "    df['GAME_ID'] = GAME_ID\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_columns(df):\n",
    "    drop_columns = ['MIN']\n",
    "    df = df.drop(columns=drop_columns)\n",
    "\n",
    "    mapper = {\n",
    "         'Match Up': 'HOME',\n",
    "         'Game Date': 'GAME_DATE_EST', \n",
    "         'W/L': 'HOME_TEAM_WINS',\n",
    "         'FG%': 'FG_PCT',\n",
    "         '3P%': 'FG3_PCT',\n",
    "         'FT%': 'FT_PCT',\n",
    "    }\n",
    "    df = df.rename(columns=mapper)\n",
    "    # make HOME true if @ is NOT in the text\n",
    "    # each game has two rows, one for each team\n",
    "    # Home team is always the team without the @\n",
    "    # TEAM   MATCH UP\n",
    "    # DAL    DAL @ POR  \n",
    "    # POR    POR vs DAL \n",
    "    df['HOME'] = df['HOME'].apply(lambda x: 0 if '@' in x else 1)\n",
    "    \n",
    "    # convert wins to home team wins\n",
    "    # incomplete games will be NaN\n",
    "    df = df[df['HOME_TEAM_WINS'].notna()]\n",
    "    # convert W/L to 1/0\n",
    "    df['HOME_TEAM_WINS'] = df['HOME_TEAM_WINS'].apply(lambda x: 1 if 'W' in x else 0)\n",
    "    # no need to do anything else, win/loss of visitor teams is not used in final dataframe\n",
    "    \n",
    "    #convert date format\n",
    "    df['GAME_DATE_EST'] = pd.to_datetime(df['GAME_DATE_EST'])\n",
    "    df['GAME_DATE_EST'] = df['GAME_DATE_EST'].dt.strftime('%Y-%m-%d')\n",
    "    df['GAME_DATE_EST'] = pd.to_datetime(df['GAME_DATE_EST'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_home_visitor(df):\n",
    "    # separate home vs visitor\n",
    "    home_df = df[df['HOME'] == 1]\n",
    "    visitor_df = df[df['HOME'] == 0]\n",
    "    \n",
    "    # HOME column no longer needed\n",
    "    home_df = home_df.drop(columns='HOME')\n",
    "    visitor_df = visitor_df.drop(columns='HOME')\n",
    "    \n",
    "    # HOME_TEAM_WINS and GAME_DATE_EST columns not needed for visitor\n",
    "    visitor_df = visitor_df.drop(columns=['HOME_TEAM_WINS','GAME_DATE_EST'])\n",
    "    \n",
    "    # rename TEAM_ID columns\n",
    "    home_df = home_df.rename(columns={'TEAM_ID':'HOME_TEAM_ID'})\n",
    "    visitor_df = visitor_df.rename(columns={'TEAM_ID':'VISITOR_TEAM_ID'})\n",
    "    \n",
    "    # merge the home and visitor data\n",
    "    df = pd.merge(home_df, visitor_df, how=\"left\", on=[\"GAME_ID\"],suffixes=('_home', '_away'))\n",
    "    \n",
    "    # add a column for SEASON\n",
    "    # determine SEASON by parsing GAME_ID \n",
    "    # (e.g. 0022200192 1st 2 digits not used, 3rd digit 2 = regular season, 4th and 5th digit = SEASON)\n",
    "    game_id = df['GAME_ID'].iloc[0]\n",
    "    season = game_id[3:5]\n",
    "    season = str(20) + season\n",
    "    df['SEASON'] = season\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_games(driver, season, dateFrom, dateTo):\n",
    "    season_types = [\"Regular+Season\", \"PlayIn\", \"Playoffs\"]\n",
    "    all_season_types = pd.DataFrame()\n",
    "\n",
    "    for season_type in season_types:\n",
    "        df = scrape_to_dataframe(driver, season, dateFrom, dateTo, season_type)\n",
    "        if not(df.empty):\n",
    "            df = convert_columns(df)\n",
    "            df = combine_home_visitor(df)\n",
    "            all_season_types = pd.concat([all_season_types, df], axis=0)\n",
    "\n",
    "    return all_season_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping season 2003 from 2003-08-01 to 2004-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2003&DateFrom=2003-08-01&DateTo=2004-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2003&DateFrom=2003-08-01&DateTo=2004-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2003&DateFrom=2003-08-01&DateTo=2004-08-01 00:00:00\n",
      "Scraping season 2004 from 2004-10-01 00:00:00 to 2005-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2004&DateFrom=2004-10-01 00:00:00&DateTo=2005-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2004&DateFrom=2004-10-01 00:00:00&DateTo=2005-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2004&DateFrom=2004-10-01 00:00:00&DateTo=2005-08-01 00:00:00\n",
      "Scraping season 2005 from 2005-10-01 00:00:00 to 2006-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2005&DateFrom=2005-10-01 00:00:00&DateTo=2006-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2005&DateFrom=2005-10-01 00:00:00&DateTo=2006-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2005&DateFrom=2005-10-01 00:00:00&DateTo=2006-08-01 00:00:00\n",
      "Scraping season 2006 from 2006-10-01 00:00:00 to 2007-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2006&DateFrom=2006-10-01 00:00:00&DateTo=2007-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2006&DateFrom=2006-10-01 00:00:00&DateTo=2007-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2006&DateFrom=2006-10-01 00:00:00&DateTo=2007-08-01 00:00:00\n",
      "Scraping season 2007 from 2007-10-01 00:00:00 to 2008-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2007&DateFrom=2007-10-01 00:00:00&DateTo=2008-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2007&DateFrom=2007-10-01 00:00:00&DateTo=2008-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2007&DateFrom=2007-10-01 00:00:00&DateTo=2008-08-01 00:00:00\n",
      "Scraping season 2008 from 2008-10-01 00:00:00 to 2009-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2008&DateFrom=2008-10-01 00:00:00&DateTo=2009-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2008&DateFrom=2008-10-01 00:00:00&DateTo=2009-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2008&DateFrom=2008-10-01 00:00:00&DateTo=2009-08-01 00:00:00\n",
      "Scraping season 2009 from 2009-10-01 00:00:00 to 2010-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2009&DateFrom=2009-10-01 00:00:00&DateTo=2010-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2009&DateFrom=2009-10-01 00:00:00&DateTo=2010-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2009&DateFrom=2009-10-01 00:00:00&DateTo=2010-08-01 00:00:00\n",
      "Scraping season 2010 from 2010-10-01 00:00:00 to 2011-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2010&DateFrom=2010-10-01 00:00:00&DateTo=2011-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2010&DateFrom=2010-10-01 00:00:00&DateTo=2011-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2010&DateFrom=2010-10-01 00:00:00&DateTo=2011-08-01 00:00:00\n",
      "Scraping season 2011 from 2011-10-01 00:00:00 to 2012-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2011&DateFrom=2011-10-01 00:00:00&DateTo=2012-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2011&DateFrom=2011-10-01 00:00:00&DateTo=2012-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2011&DateFrom=2011-10-01 00:00:00&DateTo=2012-08-01 00:00:00\n",
      "Scraping season 2012 from 2012-10-01 00:00:00 to 2013-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2012&DateFrom=2012-10-01 00:00:00&DateTo=2013-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2012&DateFrom=2012-10-01 00:00:00&DateTo=2013-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2012&DateFrom=2012-10-01 00:00:00&DateTo=2013-08-01 00:00:00\n",
      "Scraping season 2013 from 2013-10-01 00:00:00 to 2014-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2013&DateFrom=2013-10-01 00:00:00&DateTo=2014-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2013&DateFrom=2013-10-01 00:00:00&DateTo=2014-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2013&DateFrom=2013-10-01 00:00:00&DateTo=2014-08-01 00:00:00\n",
      "Scraping season 2014 from 2014-10-01 00:00:00 to 2015-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2014&DateFrom=2014-10-01 00:00:00&DateTo=2015-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2014&DateFrom=2014-10-01 00:00:00&DateTo=2015-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2014&DateFrom=2014-10-01 00:00:00&DateTo=2015-08-01 00:00:00\n",
      "Scraping season 2015 from 2015-10-01 00:00:00 to 2016-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2015&DateFrom=2015-10-01 00:00:00&DateTo=2016-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2015&DateFrom=2015-10-01 00:00:00&DateTo=2016-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2015&DateFrom=2015-10-01 00:00:00&DateTo=2016-08-01 00:00:00\n",
      "Scraping season 2016 from 2016-10-01 00:00:00 to 2017-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2016&DateFrom=2016-10-01 00:00:00&DateTo=2017-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2016&DateFrom=2016-10-01 00:00:00&DateTo=2017-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2016&DateFrom=2016-10-01 00:00:00&DateTo=2017-08-01 00:00:00\n",
      "Scraping season 2017 from 2017-10-01 00:00:00 to 2018-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2017&DateFrom=2017-10-01 00:00:00&DateTo=2018-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2017&DateFrom=2017-10-01 00:00:00&DateTo=2018-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2017&DateFrom=2017-10-01 00:00:00&DateTo=2018-08-01 00:00:00\n",
      "Scraping season 2018 from 2018-10-01 00:00:00 to 2019-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2018&DateFrom=2018-10-01 00:00:00&DateTo=2019-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2018&DateFrom=2018-10-01 00:00:00&DateTo=2019-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2018&DateFrom=2018-10-01 00:00:00&DateTo=2019-08-01 00:00:00\n",
      "Scraping season 2019 from 2019-10-01 00:00:00 to 2020-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2019&DateFrom=2019-10-01 00:00:00&DateTo=2020-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2019&DateFrom=2019-10-01 00:00:00&DateTo=2020-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2019&DateFrom=2019-10-01 00:00:00&DateTo=2020-08-01 00:00:00\n",
      "Scraping season 2020 from 2020-10-01 00:00:00 to 2021-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2020&DateFrom=2020-10-01 00:00:00&DateTo=2021-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2020&DateFrom=2020-10-01 00:00:00&DateTo=2021-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2020&DateFrom=2020-10-01 00:00:00&DateTo=2021-08-01 00:00:00\n",
      "Scraping season 2021 from 2021-10-01 00:00:00 to 2022-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2021&DateFrom=2021-10-01 00:00:00&DateTo=2022-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2021&DateFrom=2021-10-01 00:00:00&DateTo=2022-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2021&DateFrom=2021-10-01 00:00:00&DateTo=2022-08-01 00:00:00\n",
      "Scraping season 2022 from 2022-10-01 00:00:00 to 2023-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2022&DateFrom=2022-10-01 00:00:00&DateTo=2023-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2022&DateFrom=2022-10-01 00:00:00&DateTo=2023-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2022&DateFrom=2022-10-01 00:00:00&DateTo=2023-08-01 00:00:00\n",
      "Scraping season 2023 from 2023-10-01 00:00:00 to 2024-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Regular+Season&Season=2023&DateFrom=2023-10-01 00:00:00&DateTo=2024-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=PlayIn&Season=2023&DateFrom=2023-10-01 00:00:00&DateTo=2024-08-01 00:00:00\n",
      "Scraping https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023&DateFrom=2023-10-01 00:00:00&DateTo=2024-08-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "last_season = 2003\n",
    "start_date = '2003-08-01'\n",
    "new_games = pd.DataFrame()\n",
    "df_season = pd.DataFrame()\n",
    "\n",
    "for season in range(last_season, 2024):\n",
    "    end_date = datetime.strptime(f\"{season+1}-08-01\", \"%Y-%m-%d\") # use August 1st to get all games from the current season\n",
    "    print(f\"Scraping season {season} from {start_date} to {end_date}\")\n",
    "    df_season = get_games(driver, str(season), str(start_date), str(end_date))\n",
    "    new_games = pd.concat([new_games, df_season], axis=0)\n",
    "    start_date = datetime.strptime(f\"{season+1}-10-01\", \"%Y-%m-%d\") # if more than 1 season, reset start date to beginning of next season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_games.to_csv('games.csv', index=False)\n",
    "del [new_games]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_csv(\"games.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Team_home', 'GAME_DATE_EST', 'HOME_TEAM_WINS', 'PTS_home', 'FGM_home',\n",
       "       'FGA_home', 'FG_PCT_home', '3PM_home', '3PA_home', 'FG3_PCT_home',\n",
       "       'FTM_home', 'FTA_home', 'FT_PCT_home', 'OREB_home', 'DREB_home',\n",
       "       'REB_home', 'AST_home', 'STL_home', 'BLK_home', 'TOV_home', 'PF_home',\n",
       "       '+/-_home', 'HOME_TEAM_ID', 'GAME_ID', 'Team_away', 'PTS_away',\n",
       "       'FGM_away', 'FGA_away', 'FG_PCT_away', '3PM_away', '3PA_away',\n",
       "       'FG3_PCT_away', 'FTM_away', 'FTA_away', 'FT_PCT_away', 'OREB_away',\n",
       "       'DREB_away', 'REB_away', 'AST_away', 'STL_away', 'BLK_away', 'TOV_away',\n",
       "       'PF_away', '+/-_away', 'VISITOR_TEAM_ID', 'SEASON'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove preseason games (GAME_ID begins with a 1)\n",
    "games = games[games['GAME_ID'] > 20000000]\n",
    "\n",
    "#flag postseason games (GAME_ID begins with >2)\n",
    "games['PLAYOFF'] = (games['GAME_ID'] >= 30000000).astype('int8')\n",
    "\n",
    "#remove duplicates (each GAME_ID should be unique)\n",
    "games = games[~games.duplicated(subset=['GAME_ID'])]\n",
    "\n",
    "#drop unnecessary fields\n",
    "# drop_fields = ['Unnamed: 0']\n",
    "# games = games.drop(drop_fields,axis=1)\n",
    "\n",
    "games['TARGET'] = games['HOME_TEAM_WINS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.to_csv('transformed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
